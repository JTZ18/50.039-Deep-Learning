{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "# Others\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 42  # A popular choice, but the specific number doesn't matter much\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# If you are using CUDA, you might want to add:\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # For multi-GPU.\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I doubt we'll use this tbh\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.dataframe = pd.read_excel(path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Change inputs and outputs accordingly\n",
    "        \"\"\"\n",
    "\n",
    "        # Select columns corresponding to the different inputs and outputs from the dataframe we just created.\n",
    "        # And convert to PyTorch tensors with the right dtype\n",
    "        x1 = torch.tensor(self.dataframe.iloc[idx, 0], dtype=torch.float64)\n",
    "        x2 = torch.tensor(self.dataframe.iloc[idx, 1], dtype=torch.float64)\n",
    "        y = torch.tensor(self.dataframe.iloc[idx, 2], dtype=torch.float64)\n",
    "        \n",
    "        # Assemble all input features in a single inputs tensor with 2 columns and rows for each sample in the dataset.\n",
    "        inputs = torch.stack([x1, x2], dim=0)\n",
    "        return inputs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Dataset is gotten from customdataset above\n",
    "dataset = CustomDataset(\"\")\n",
    "\n",
    "# Assuming `dataset` is your Dataset object\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.7)  # 70% for training\n",
    "valid_size = int(total_size * 0.15)  # 15% for validation\n",
    "test_size = total_size - train_size - valid_size  # Remaining 15% for testing\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64  # Adjust as per your requirement\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Blocks of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseReLU(torch.nn.Module):\n",
    "    def __init__(self, n_x, n_y):\n",
    "        super().__init__()\n",
    "        # Define Linear layer using the nn.Linear()\n",
    "        self.fc = torch.nn.Linear(n_x, n_y)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Wx + b operation\n",
    "        # Using ReLU operation as activation after\n",
    "        return torch.relu(self.fc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNet(torch.nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_y):\n",
    "        super().__init__()\n",
    "        # Define the correct number of Dense + ReLU layers based on n_h,\n",
    "        # followed by one final Dense + Softmax layer\n",
    "        values = [n_x] + n_h\n",
    "        self.processing_layers = [DenseReLU(values[i], values[i + 1]) for i in range(len(values) - 1)]\n",
    "        self.processing_layers += [DenseNoReLU(n_h[-1], n_y)]\n",
    "        \n",
    "        # Combine all layers\n",
    "        # Important: note the * symbol before the list of layers in self.processing_layers\n",
    "        # Not sure what it does? Check the *args and **kwargs concepts in Python.\n",
    "        self.combined_layers = torch.nn.Sequential(*self.processing_layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Flatten images (transform them from 28x28 2D matrices to 784 1D vectors)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Pass through all four layers\n",
    "        out = self.combined_layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer function\n",
    "\n",
    "Note: Test is the VALIDATION set here\n",
    "\n",
    "Essentially, we want to pick the best validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, train_loader, test_loader):\n",
    "    \n",
    "    # History for train acc, test acc\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
    "\n",
    "    # Training model\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Go trough all samples in train dataset\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Get from dataloader and send to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Display\n",
    "            if (i+1) % 25 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}')\n",
    "\n",
    "        # Compute model train accuracy on test after all samples have been seen using test samples\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in train_loader:\n",
    "                # Get images and labels from test loader\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass and predict class using max\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Check if predicted class matches label and count numbler of correct predictions\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        # Compute final accuracy and display\n",
    "        train_accuracy = correct/total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.4f}')\n",
    "        train_accs.append(train_accuracy)\n",
    "        \n",
    "        # Compute model test accuracy on test after all samples have been seen using test samples\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                # Get images and labels from test loader\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass and predict class using max\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Check if predicted class matches label and count numbler of correct predictions\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        # Compute final accuracy and display\n",
    "        test_accuracy = correct/total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {test_accuracy:.4f}')\n",
    "        test_accs.append(test_accuracy)\n",
    "        \n",
    "    # Return\n",
    "    return train_accs, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "We need to loop through and do some hyperparameter tuning here. Ideally with RandomSearch\n",
    "\n",
    "Below is a placeholder display of data. We'll definitely have to change it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 7))\n",
    "plt.plot(train_accs1, \"r-\", label = \"Model 1 train acc.\")\n",
    "plt.plot(test_accs1, \"b-\", label = \"Model 1 test acc.\")\n",
    "plt.plot(train_accs2, \"r--\", label = \"Model 2 train acc.\")\n",
    "plt.plot(test_accs2, \"b--\", label = \"Model 2 test acc.\")\n",
    "plt.plot(train_accs3, \"r:\", label = \"Model 3 train acc.\")\n",
    "plt.plot(test_accs3, \"b:\", label = \"Model 3 test acc.\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.ylim([0.9, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Testing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Temporarily set all the requires_grad flag to false\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate over test data\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)  # Get model predictions\n",
    "        \n",
    "        # For classification, the prediction is the index of the max log-probability\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test dataset: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
